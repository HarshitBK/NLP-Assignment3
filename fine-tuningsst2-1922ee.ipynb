{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T08:05:52.788895Z","iopub.status.busy":"2024-11-20T08:05:52.788362Z","iopub.status.idle":"2024-11-20T08:06:03.574674Z","shell.execute_reply":"2024-11-20T08:06:03.573803Z","shell.execute_reply.started":"2024-11-20T08:05:52.788835Z"},"trusted":true},"outputs":[],"source":["!pip install evaluate "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T08:06:03.576555Z","iopub.status.busy":"2024-11-20T08:06:03.576245Z","iopub.status.idle":"2024-11-20T08:06:26.165973Z","shell.execute_reply":"2024-11-20T08:06:26.16504Z","shell.execute_reply.started":"2024-11-20T08:06:03.576523Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","from datasets import load_dataset, DatasetDict\n","from datasets import Dataset, DatasetDict\n","from sklearn.model_selection import train_test_split\n","import torch\n","import evaluate\n","import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T08:06:31.675713Z","iopub.status.busy":"2024-11-20T08:06:31.675045Z","iopub.status.idle":"2024-11-20T08:06:31.685894Z","shell.execute_reply":"2024-11-20T08:06:31.684952Z","shell.execute_reply.started":"2024-11-20T08:06:31.675677Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","dataset_dir = \"/kaggle/input/tokenized-dataset/\"\n","print(\"Contents of the dataset directory:\")\n","print(os.listdir(dataset_dir))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T08:06:33.982885Z","iopub.status.busy":"2024-11-20T08:06:33.982559Z","iopub.status.idle":"2024-11-20T08:06:50.974666Z","shell.execute_reply":"2024-11-20T08:06:50.973769Z","shell.execute_reply.started":"2024-11-20T08:06:33.982859Z"},"trusted":true},"outputs":[],"source":["file_path = \"/kaggle/input/tokenized-dataset/Tokenized_Data.txt\"\n","\n","with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","    lines = file.readlines()\n","\n","print(\"First 5 lines of the tokenized dataset:\")\n","for line in lines[:5]:\n","    print(line.strip())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T08:06:54.259972Z","iopub.status.busy":"2024-11-20T08:06:54.259271Z","iopub.status.idle":"2024-11-20T08:07:59.151503Z","shell.execute_reply":"2024-11-20T08:07:59.150582Z","shell.execute_reply.started":"2024-11-20T08:06:54.259937Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","\n","\n","model_name = \"meta-llama/Llama-3.2-1B\"\n","# Access_token goes here\n"," \n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=access_token)\n","model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=access_token)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","total_params = sum(p.numel() for p in model.parameters())\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f\"Total Parameters: {total_params:,}\")\n","print(f\"Trainable Parameters: {trainable_params:,}\")"]},{"cell_type":"markdown","metadata":{},"source":["SST"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T08:08:01.436732Z","iopub.status.busy":"2024-11-20T08:08:01.436261Z","iopub.status.idle":"2024-11-20T08:08:01.44123Z","shell.execute_reply":"2024-11-20T08:08:01.440358Z","shell.execute_reply.started":"2024-11-20T08:08:01.436699Z"},"trusted":true},"outputs":[],"source":["import random\n","import numpy as np\n","import torch\n","from sklearn.model_selection import train_test_split\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    AutoModelForQuestionAnswering,\n","    Trainer,\n","    TrainingArguments,\n","    default_data_collator,\n",")\n","import evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T08:08:04.725675Z","iopub.status.busy":"2024-11-20T08:08:04.725301Z","iopub.status.idle":"2024-11-20T08:08:07.8564Z","shell.execute_reply":"2024-11-20T08:08:07.855543Z","shell.execute_reply.started":"2024-11-20T08:08:04.725644Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","\n","# Loading SST-2 dataset\n","sst2_dataset = load_dataset(\"glue\", \"sst2\")\n","\n","SEED = 1\n","split_sst2 = sst2_dataset[\"train\"].train_test_split(test_size=0.2, seed=SEED)\n","train_sst2 = split_sst2[\"train\"]\n","test_sst2 = split_sst2[\"test\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T08:08:10.841406Z","iopub.status.busy":"2024-11-20T08:08:10.84038Z","iopub.status.idle":"2024-11-20T08:08:20.656507Z","shell.execute_reply":"2024-11-20T08:08:20.655548Z","shell.execute_reply.started":"2024-11-20T08:08:10.841353Z"},"trusted":true},"outputs":[],"source":["def preprocess_sst2(examples):\n","    return tokenizer_sst2(\n","        examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128\n","    )\n","# Loading tokenizer for classification\n","tokenizer_sst2 = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","train_sst2 = train_sst2.map(preprocess_sst2, batched=True)\n","test_sst2 = test_sst2.map(preprocess_sst2, batched=True)\n","\n","train_sst2.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n","test_sst2.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T08:08:23.348603Z","iopub.status.busy":"2024-11-20T08:08:23.348177Z","iopub.status.idle":"2024-11-20T08:51:34.243172Z","shell.execute_reply":"2024-11-20T08:51:34.24246Z","shell.execute_reply.started":"2024-11-20T08:08:23.34857Z"},"trusted":true},"outputs":[],"source":["import evaluate\n","import os\n","import numpy as np\n","from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n","\n","model_sst2 = AutoModelForSequenceClassification.from_pretrained(\"meta-llama/Llama-3.2-1B\", num_labels=2)\n","\n","# Defining training arguments\n","training_args_sst2 = TrainingArguments(\n","    output_dir=\"./sst2_model\",  \n","    eval_strategy=\"epoch\", \n","    save_strategy=\"epoch\",  \n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    seed=SEED,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    save_total_limit=3,  \n","    overwrite_output_dir=True,  \n",")\n","\n","metric = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)\n","\n","checkpoint = None\n","if os.path.isdir(training_args_sst2.output_dir):\n","    checkpoint = os.path.join(training_args_sst2.output_dir, \"checkpoint-last\")\n","\n","trainer_sst2 = Trainer(\n","    model=model_sst2,\n","    args=training_args_sst2,\n","    train_dataset=train_sst2,\n","    eval_dataset=test_sst2,\n","    tokenizer=tokenizer_sst2,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer_sst2.train(resume_from_checkpoint=checkpoint)\n","trainer_sst2.save_model(training_args_sst2.output_dir)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T08:59:40.822711Z","iopub.status.busy":"2024-11-20T08:59:40.822321Z","iopub.status.idle":"2024-11-20T08:59:40.831431Z","shell.execute_reply":"2024-11-20T08:59:40.830574Z","shell.execute_reply.started":"2024-11-20T08:59:40.822679Z"},"trusted":true},"outputs":[],"source":["# FIne-tuned parameters\n","total_params = sum(p.numel() for p in model_sst2.parameters())  \n","trainable_params = sum(p.numel() for p in model_sst2.parameters() if p.requires_grad)  \n","\n","print(f\"Total Parameters in Fine-Tuned Model: {total_params:,}\")\n","print(f\"Trainable Parameters in Fine-Tuned Model: {trainable_params:,}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T09:05:45.890327Z","iopub.status.busy":"2024-11-20T09:05:45.889985Z","iopub.status.idle":"2024-11-20T09:24:09.074049Z","shell.execute_reply":"2024-11-20T09:24:09.073169Z","shell.execute_reply.started":"2024-11-20T09:05:45.890295Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import pipeline, AutoTokenizer\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","def get_gpu_with_most_memory():\n","    num_gpus = torch.cuda.device_count()\n","    if num_gpus == 0:\n","        return \"cpu\" \n","    \n","    max_memory = 0\n","    selected_device = 0\n","    for i in range(num_gpus):\n","        memory_allocated = torch.cuda.memory_allocated(i)\n","        memory_reserved = torch.cuda.memory_reserved(i)\n","        total_memory = torch.cuda.get_device_properties(i).total_memory\n","        \n","        free_memory = total_memory - memory_allocated - memory_reserved\n","        \n","        if free_memory > max_memory:\n","            max_memory = free_memory\n","            selected_device = i\n","    \n","    return f\"cuda:{selected_device}\"\n","\n","\n","device = torch.device(get_gpu_with_most_memory())\n","\n","tokenizer_sst2 = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","\n","def get_zero_shot_model():\n","    zero_shot_classifier = pipeline(\n","        \"zero-shot-classification\",\n","        model=\"meta-llama/Llama-3.2-1B\",\n","        tokenizer=\"meta-llama/Llama-3.2-1B\",\n","        use_auth_token=\"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\",\n","        device=device.index if device.type == 'cuda' else -1  \n","    )\n","    return zero_shot_classifier\n","\n","def int_to_label(int_label):\n","    label_map = {0: \"negative\", 1: \"positive\"}\n","    return label_map.get(int_label, \"unknown\")\n","\n","def calculate_metrics_zero_shot(zero_shot_classifier, test_dataset, labels):\n","    all_preds = []\n","    all_labels = []\n","    \n","    for batch in test_dataset:\n","        text = tokenizer_sst2.decode(batch['input_ids'], skip_special_tokens=True)\n","        \n","        true_label = int_to_label(batch['label'].item())  \n","\n","        result = zero_shot_classifier(text, candidate_labels=labels)\n","        predicted_label = result['labels'][0]  \n","\n","        all_preds.append(predicted_label)\n","        all_labels.append(true_label)\n","    \n","    accuracy = accuracy_score(all_labels, all_preds)\n","    precision = precision_score(all_labels, all_preds, average='binary', pos_label='positive')\n","    recall = recall_score(all_labels, all_preds, average='binary', pos_label='positive')\n","    f1 = f1_score(all_labels, all_preds, average='binary', pos_label='positive')\n","    \n","    return accuracy, precision, recall, f1\n","\n","labels = [\"positive\", \"negative\"]  \n","\n","\n","zero_shot_classifier = get_zero_shot_model()\n","accuracy_zero_shot, precision_zero_shot, recall_zero_shot, f1_zero_shot = calculate_metrics_zero_shot(zero_shot_classifier, test_sst2, labels)\n","\n","print(f\"Zero-shot Model Metrics:\")\n","print(f\"Accuracy: {accuracy_zero_shot}\")\n","print(f\"Precision: {precision_zero_shot}\")\n","print(f\"Recall: {recall_zero_shot}\")\n","print(f\"F1: {f1_zero_shot}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T09:45:42.899425Z","iopub.status.busy":"2024-11-20T09:45:42.898745Z","iopub.status.idle":"2024-11-20T09:46:54.027184Z","shell.execute_reply":"2024-11-20T09:46:54.026348Z","shell.execute_reply.started":"2024-11-20T09:45:42.899395Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n","import numpy as np\n","import evaluate\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","def get_gpu_with_most_memory():\n","    num_gpus = torch.cuda.device_count()\n","    if num_gpus == 0:\n","        return \"cpu\"  \n","\n","    max_free_memory = 0\n","    selected_device = 0\n","    for i in range(num_gpus):\n","        free_memory = torch.cuda.get_device_properties(i).total_memory - torch.cuda.memory_reserved(i)\n","        if free_memory > max_free_memory:\n","            max_free_memory = free_memory\n","            selected_device = i\n","\n","    return f\"cuda:{selected_device}\"\n","\n","device = torch.device(get_gpu_with_most_memory())\n","\n","\n","model_fine_tuned = AutoModelForSequenceClassification.from_pretrained(\n","    \"/kaggle/working/sst2_model\",\n","    num_labels=2\n",")\n","model_fine_tuned.to(device) \n","\n","\n","training_args_fine_tuned = TrainingArguments(\n","    output_dir=\"./fine_tuned_model\",\n","    per_device_eval_batch_size=16,\n","    no_cuda=device.type == \"cpu\", \n","    evaluation_strategy=\"epoch\",  \n","    save_strategy=\"epoch\", \n","    load_best_model_at_end=True,  \n",")\n","\n","metric = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    accuracy = metric.compute(predictions=predictions, references=labels)['accuracy']\n","    precision = precision_score(labels, predictions, average='binary')\n","    recall = recall_score(labels, predictions, average='binary')\n","    f1 = f1_score(labels, predictions, average='binary')\n","    \n","    return {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","    }\n","\n","trainer_fine_tuned = Trainer(\n","    model=model_fine_tuned,\n","    args=training_args_fine_tuned,\n","    eval_dataset=test_sst2,  \n","    compute_metrics=compute_metrics,\n",")\n","\n","eval_results_fine_tuned = trainer_fine_tuned.evaluate()\n","\n","print(f\"Fine-tuned Model Metrics:\")\n","print(f\"Accuracy: {eval_results_fine_tuned['eval_accuracy']}\")\n","print(f\"Precision: {eval_results_fine_tuned['eval_precision']}\")\n","print(f\"Recall: {eval_results_fine_tuned['eval_recall']}\")\n","print(f\"F1: {eval_results_fine_tuned['eval_f1']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T09:47:00.852317Z","iopub.status.busy":"2024-11-20T09:47:00.851376Z","iopub.status.idle":"2024-11-20T09:47:00.862023Z","shell.execute_reply":"2024-11-20T09:47:00.861039Z","shell.execute_reply.started":"2024-11-20T09:47:00.852267Z"},"trusted":true},"outputs":[],"source":["print(\"Zero-shot Model Metrics:\")\n","print(f\"Accuracy: {accuracy_zero_shot}\")\n","print(f\"Precision: {precision_zero_shot}\")\n","print(f\"Recall: {recall_zero_shot}\")\n","print(f\"F1: {f1_zero_shot}\")\n","\n","print(\"\\nFine-tuned Model Metrics:\")\n","print(f\"Accuracy: {eval_results_fine_tuned['eval_accuracy']}\")\n","print(f\"Precision: {eval_results_fine_tuned['eval_precision']}\")\n","print(f\"Recall: {eval_results_fine_tuned['eval_recall']}\")\n","print(f\"F1: {eval_results_fine_tuned['eval_f1']}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":6096226,"sourceId":9919494,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
